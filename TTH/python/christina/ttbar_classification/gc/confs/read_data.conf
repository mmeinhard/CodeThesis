[global]
variable markers   = @
task        = UserTask
backend     = local
workdir = ${CMSSW_BASE}/src/TTH/Plotting/python/christina/ttbar_classification/gc/work.read_data

[jobs]

[local]
queue = short.q

[task]
wall time = 1:00
memory = 4000

[UserTask]
executable  = read_data.sh
subst files = read_data.sh
dataset splitter = FileBoundarySplitter
dataset refresh  = 1:00
files per job = 100
input files = env.sh common.sh
dataset =
;        ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/datasets/Nov30_ttbb/TT_TuneCUETP8M2T4_13TeV-powheg-pythia8.txt
         ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/datasets/Nov30_ttbb/TTTo2L2Nu_TuneCUETP8M2_ttHtranche3_13TeV-powheg-pythia8.txt
         ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/datasets/Nov30_ttbb/TTToSemilepton_TuneCUETP8M2_ttHtranche3_13TeV-powheg-pythia8.txt
;        ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/datasets/nano_05Feb2018/step2/TTTo2L2Nu_TuneCUETP8M2_ttHtranche3_13TeV-powheg-pythia8.txt
;        ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/datasets/nano_05Feb2018/step2/TTToSemilepton_TuneCUETP8M2_ttHtranche3_13TeV-powheg-pythia8.txt
;        ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/datasets/nano_05Feb2018/step2/ttHTobb_M125_TuneCUETP8M2_ttHtranche3_13TeV-powheg-pythia8.txt

[storage]
scratch space used = 5000
scratch space left = 2000
se output files = dataframe.csv 
se output pattern = job_@MY_JOBID@_@X@
se path = dir://$HOME/tth/gc/bdt/${GC_TASK_ID}/${DATASETPATH}


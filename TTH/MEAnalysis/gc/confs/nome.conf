[global]
variable markers   = @
task        = UserTask
backend     = local
workdir = ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/work.nome

[local]
queue = all.q

[UserTask]
executable  = meanalysis-heppy.sh
#dataset splitter = EventBoundarySplitter
#events per job = 10000
dataset splitter = FileBoundarySplitter
files per job = 1
subst files = meanalysis-heppy.sh
input files = env.sh common.sh
dataset =
#    datasets/Feb6_leptonic_nome/TT_TuneCUETP8M2T4_13TeV-powheg-pythia8_jpata-Feb6_leptonic_nome-73161cecf545d5628b07ac5ac6fd2e49.txt
#    datasets/Feb1_leptonic_nome/ttHTobb_M125_TuneCUETP8M2_ttHtranche3_13TeV-powheg-pythia8.txt
#    datasets/Apr16/ttHTobb_M125_TuneCP5_13TeV-powheg-pythia8.txt
#    datasets/May14_v1/ttHTobb_M125_TuneCP5_13TeV-powheg-pythia8.txt
    datasets/May14_v1/TTToSemiLeptonic_TuneCP5_PSweights_13TeV-powheg-pythia8.txt
    datasets/May14_v1/TTTo2L2Nu_TuneCP5_13TeV-powheg-pythia8.txt

[parameters]
parameters = me_conf
me_conf = default

[storage]
scratch space used = 5000
scratch space left = 1000
se output files = training.csv
#se output files = out.root training.csv
se output pattern = job_@MY_JOBID@_@X@
#se path = dir:///shome/$USER/tth/2017/gc/meanalysis/${GC_TASK_ID}/${DATASETPATH}/
se path = srm://t3se01.psi.ch:8443/srm/managerv2?SFN=/pnfs/psi.ch/cms/trivcat/store/user/$USER/tth/meanalysis/${GC_TASK_ID}/${DATASETPATH}/

[task]
wall time = 10:00
memory = 5000

[global]
variable markers   = @
task        = UserTask
backend     = local
workdir = ${CMSSW_BASE}/src/TTH/MEAnalysis/gc/work.projectSkimFH_SixJetControl

[local]
queue = short.q

[task]
memory = 6000

[jobs]
wall time = 1:30
in flight = 100

[UserTask]
executable  = projectSkimFH.sh
dataset splitter = FileBoundarySplitter
dataset refresh  = 4:00
files per job = 10
input files = env.sh common.sh
dataset =
#    datasets/ttH_AH_v1/QCD_HT1000to1500_TuneCP5_13TeV-madgraph-pythia8.txt
#    datasets/ttH_AH_v1/QCD_HT1500to2000_TuneCP5_13TeV-madgraph-pythia8.txt
#    datasets/ttH_AH_v1/QCD_HT2000toInf_TuneCP5_13TeV-madgraph-pythia8.txt
#    datasets/ttH_AH_v1/QCD_HT300to500_TuneCP5_13TeV-madgraph-pythia8.txt
#    datasets/ttH_AH_v1/QCD_HT500to700_TuneCP5_13TeV-madgraph-pythia8.txt
#    datasets/ttH_AH_v1/QCD_HT700to1000_TuneCP5_13TeV-madgraph-pythia8.txt
    #datasets/ttH_AH_v1/TTToHadronic_TuneCP5_13TeV-powheg-pythia8.txt
#    datasets/ttH_AH_noME_v1/TTToHadronic_TuneCP5_13TeV-powheg-pythia8.txt
#    datasets/ttH_AH_v1/ttHTobb_M125_TuneCP5_13TeV-powheg-pythia8.txt
#    datasets/ttH_AH_v1/ttHToNonbb_M125_TuneCP5_13TeV-powheg-pythia8.txt
#    datasets/ttH_AH_v1/BTagCSV.txt
#    datasets/ttH_AH_v1/JetHT.txt
#    datasets/ttH_AH_TriggerSF_v1/TTToSemiLeptonic_TuneCP5_PSweights_13TeV-powheg-pythia8.txt
#     datasets/ttH_AH_TriggerSF_v1/TTTo2L2Nu_TuneCP5_13TeV-powheg-pythia8.txt
#############
#      datasets/ttH_AH_noME_passAll_v1/BTagCSV.txt
      datasets/ttH_AH_noME_passAll_v1/JetHT.txt
      datasets/ttH_AH_TriggerSF_v1p1/TTToHadronic_TuneCP5_13TeV-powheg-pythia8.txt
[storage]
scratch space used = 20000
scratch space left = 20000
se output files = out.root
se output pattern = job_@MY_JOBID@_@X@
se path = dir://$HOME/tth/gc/projectSkimFH/${GC_TASK_ID}/${DATASETPATH}/

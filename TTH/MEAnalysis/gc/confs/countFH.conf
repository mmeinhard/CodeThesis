[global]
variable markers   = @
task        = UserTask           ; Job uses user written scripts
backend     = local              ; Send to local batch system
workdir = $CMSSW_BASE/src/TTH/MEAnalysis/gc/work.count_2

[jobs]
wall time = 1:30:00

[UserTask]
executable  = countreCalc.sh
dataset splitter = FileBoundarySplitter
files per job = 50
input files = common.sh env.sh
dataset =
    datasets/ttH_AH_v1/ttHTobb_M125_TuneCP5_13TeV-powheg-pythia8.txt
    datasets/ttH_AH_v1/ttHToNonbb_M125_TuneCP5_13TeV-powheg-pythia8.txt
    datasets/ttH_AH_v1/QCD_HT1000to1500_TuneCP5_13TeV-madgraph-pythia8.txt
    datasets/ttH_AH_v1/QCD_HT1500to2000_TuneCP5_13TeV-madgraph-pythia8.txt
#    datasets/ttH_AH_v1/QCD_HT2000toInf_TuneCP5_13TeV-madgraph-pythia8.txt
    datasets/ttH_AH_v1/QCD_HT300to500_TuneCP5_13TeV-madgraph-pythia8.txt
    datasets/ttH_AH_v1/QCD_HT500to700_TuneCP5_13TeV-madgraph-pythia8.txt
    datasets/ttH_AH_v1/QCD_HT700to1000_TuneCP5_13TeV-madgraph-pythia8.txt
    datasets/ttH_AH_v1/TTToHadronic_TuneCP5_13TeV-powheg-pythia8.txt
    datasets/ttH_AH_TriggerSF_v1/TTTo2L2Nu_TuneCP5_13TeV-powheg-pythia8.txt
    datasets/ttH_AH_TriggerSF_v1/TTToSemiLeptonic_TuneCP5_PSweights_13TeV-powheg-pythia8.txt


	
[storage]
scratch space used = 5000
scratch space left = 1000
se output files = out.root
se output pattern = job_@MY_JOBID@_@X@
se path = dir://$HOME/tth/gc/count/${GC_TASK_ID}/${DATASETPATH}/
